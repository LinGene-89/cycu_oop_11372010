import json
import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup

SEARCH_URL = "https://ebus.gov.taipei/"

# è¦æœå°‹çš„é—œéµå­—ï¼Œå¯æ“´å……
KEYWORDS = [str(i) for i in range(10)] + ["ç´…", "ç¶ ", "è—", "å¹¹ç·š", "å¸‚å€", "å°", "å…§", "å—", "åŒ—", "æ±", "è¥¿"]

async def fetch_routes_from_search():
    routes = {}

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False, slow_mo=80)
        page = await browser.new_page()
        await page.goto(SEARCH_URL)

        # é»é–‹å³ä¸Šè§’çš„æŸ¥è©¢æ¬„
        await page.click("#navSearchBtn")
        await page.wait_for_selector("input#SearchInput", timeout=10000)

        for keyword in KEYWORDS:
            print(f"ğŸ” æœå°‹é—œéµå­—: {keyword}")
            await page.fill("input#SearchInput", "")
            await page.fill("input#SearchInput", keyword)
            await page.click("button#btnSearch")

            try:
                await page.wait_for_selector("div.search-item", timeout=8000)
            except:
                print("âš ï¸ ç„¡æœå°‹çµæœ")
                continue

            html = await page.content()
            soup = BeautifulSoup(html, "html.parser")
            items = soup.select("div.search-item")

            for item in items:
                a_tag = item.select_one("a")
                if a_tag and "routeid=" in a_tag["href"]:
                    route_id = a_tag["href"].split("routeid=")[-1]
                    route_name = a_tag.get_text(strip=True)
                    routes[route_id] = route_name

        await browser.close()

    return routes

async def save_routes_json():
    routes = await fetch_routes_from_search()
    print(f"âœ… å…±æŠ“åˆ° {len(routes)} æ¢ç¨ç«‹è·¯ç·š")

    # å„²å­˜æˆ JSON
    with open("routes_basic.json", "w", encoding="utf-8") as f:
        json.dump(routes, f, ensure_ascii=False, indent=2)

    print("âœ… è³‡æ–™å·²å„²å­˜ç‚º routes_basic.json")

# ä¸»ç¨‹å¼
if __name__ == "__main__":
    asyncio.run(save_routes_json())
